{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "559ed8d9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# SETUP IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ce7b3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\singgih.dwindaru\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "from embeddings.encoder import TextEncoder\n",
    "from chunking.splitter import sentence_split, fixed_token_split\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc2b324",
   "metadata": {},
   "source": [
    "**sample text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20503644",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Artificial intelligence is the simulation of human intelligence in machines.\n",
    "These machines are programmed to think like humans and mimic their actions.\n",
    "AI has many applications in today's society including search engines, chatbots, and self-driving cars.\n",
    "\"\"\"\n",
    "\n",
    "query = \"What is artificial intelligence?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadeddec",
   "metadata": {},
   "source": [
    "```python\n",
    "init encoder and chunk text\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d91f40fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Error while downloading from https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/model.safetensors: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks:\n",
      "- \n",
      "Artificial intelligence is the simulation of human intelligence in machines.\n",
      "- These machines are programmed to think like humans and mimic their actions.\n",
      "- AI has many applications in today's society including search engines, chatbots, and self-driving cars.\n"
     ]
    }
   ],
   "source": [
    "encoder = TextEncoder()\n",
    "\n",
    "chunks = sentence_split(text)  # or use fixed_token_split(text, max_tokens=20)\n",
    "\n",
    "print(\"Chunks:\")\n",
    "for c in chunks:\n",
    "    print(\"-\", c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a7fe99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode everything\n",
    "full_emb = encoder.encode_single(text)\n",
    "chunk_embs = encoder.encode(chunks)\n",
    "query_emb = encoder.encode_single(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0e7ecc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîµ Full text similarity: 0.8069043\n",
      "üü¢ Chunk similarities:\n",
      "  [0] 0.8004 - \n",
      "Artificial intelligence is the simulation of human intelligence in machines.\n",
      "  [1] 0.4317 - These machines are programmed to think like humans and mimic their actions.\n",
      "  [2] 0.5434 - AI has many applications in today's society including search engines, chatbots, and self-driving cars.\n",
      "\n",
      "‚≠ê Best chunk match score: 0.8003577\n"
     ]
    }
   ],
   "source": [
    "# similarity scores\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def cosine(vec1: List[float], vec2: List[float]):\n",
    "    return cosine_similarity([vec1], [vec2])[0][0]\n",
    "\n",
    "print(\"üîµ Full text similarity:\", cosine(query_emb, full_emb))\n",
    "\n",
    "chunk_sims = [cosine(query_emb, chunk) for chunk in chunk_embs]\n",
    "print(\"üü¢ Chunk similarities:\")\n",
    "for i, (chunk, score) in enumerate(zip(chunks, chunk_sims)):\n",
    "    print(f\"  [{i}] {score:.4f} - {chunk}\")\n",
    "    \n",
    "max_chunk = max(chunk_sims)\n",
    "print(\"\\n‚≠ê Best chunk match score:\", max_chunk)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
